<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title><![CDATA[Machine Learning]]></title>
        <description><![CDATA[Machine Learning]]></description>
        <link>http://machinelearning.engineering/</link>
        <generator>The Grid</generator>
        <lastBuildDate>Sun, 29 Apr 2018 11:44:12 GMT</lastBuildDate>
        <atom:link href="http://machinelearning.engineering/rss.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Sun, 29 Apr 2018 11:44:11 GMT</pubDate>
        <item>
            <title><![CDATA[RemoteML - Remote Machine Learning Jobs: AI, Data Science, Deep Learning.]]></title>
            <description><![CDATA[<article><h1>RemoteML - Remote Machine Learning Jobs: AI, Data Science, Deep Learning.</h1><p>The best candidates are distributed all over the world. Find the best Machine Learning, Deep Learning and Data Science talent all over the world on RemoteML</p><img src="https://remoteml.com/static/img/remoteml-wallpaper.jpg"></article>]]></description>
            <link>https://remoteml.com/</link>
            <guid isPermaLink="false">9fd435ca-783d-4191-8a3f-e133f286ee89</guid>
            <pubDate>Sun, 29 Apr 2018 11:44:10 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[PyTorch - Internal Architecture Tour]]></title>
            <description><![CDATA[<article><h1>PyTorch - Internal Architecture Tour</h1><p>Introduction Short intro to Python extension objects in C/C++ Zero-copy PyTorch Tensor to Numpy and vice-versa Tensor Storage Shared Memory DLPack: a hope for the Deep Learning frameworks Babel Introduction This post is a tour around the PyTorch codebase, it is meant to be a guide for the architectural design of</p><img src="https://pbs.twimg.com/profile_images/634134295607668736/FdZjcEl2_400x400.jpg"></article>]]></description>
            <link>http://blog.christianperone.com/2018/03/pytorch-internal-architecture-tour/</link>
            <guid isPermaLink="false">fd5cd942-6011-4d93-b909-300a3c3309f8</guid>
            <pubDate>Sun, 29 Apr 2018 11:44:05 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Introduction to Recurrent Neural Networks in Pytorch - CPUheater]]></title>
            <description><![CDATA[<article><h1>Introduction to Recurrent Neural Networks in Pytorch - CPUheater</h1><p>This tutorial is intended for someone who wants to understand how Recurrent Neural Network works, no prior knowledge about RNN is required. We will implement the most simple RNN model - Elman Recurrent Neural Network. To get a better understanding of RNNs, we will build it from scratch using Pytorch tensor package and autograd library.</p><img src="https://www.cpuheater.com/wp-content/uploads/2017/12/RNN-logo-7.png"></article>]]></description>
            <link>https://www.cpuheater.com/deep-learning/introduction-to-recurrent-neural-networks-in-pytorch/</link>
            <guid isPermaLink="false">80bf0fb1-0c88-4c37-bf85-a2bbbde8df75</guid>
            <pubDate>Sun, 29 Apr 2018 11:44:02 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Embed, encode, attend, predict: The new deep learning formula for state-of-the-art NLP models · Blog · Explosion AI]]></title>
            <description><![CDATA[<article><h1>Embed, encode, attend, predict: The new deep learning formula for state-of-the-art NLP models &middot; Blog &middot; Explosion AI</h1><p>Over the last six months, a powerful new neural network playbook has come together for Natural Language Processing. The new approach can be summarised as a simple four-step formula: embed, encode, attend, predict.</p><img src="https://explosion.ai/blog/img/deep-learning-formula-nlp.jpg"></article>]]></description>
            <link>https://explosion.ai/blog/deep-learning-formula-nlp</link>
            <guid isPermaLink="false">6a3f55bf-39d9-4e7f-9dbc-e854983c5774</guid>
            <pubDate>Mon, 23 Apr 2018 14:31:15 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[The Building Blocks of Interpretability]]></title>
            <description><![CDATA[<article><h1>The Building Blocks of Interpretability</h1><p>With the growing success of neural networks, there is a corresponding need to be able to explain their decisions&thinsp;-&thinsp;including building con&filig;dence about how they will behave in the real-world, detecting model bias, and for scienti&filig;c curiosity. In order to do so, we need to both construct deep abstractions and reify (or instantiate) them in rich interfaces .</p><img src="https://distill.pub/2018/building-blocks/thumbnail.jpg"></article>]]></description>
            <link>https://distill.pub/2018/building-blocks/</link>
            <guid isPermaLink="false">f27e084e-1fdc-4339-ab5f-6587563e08b4</guid>
            <pubDate>Mon, 02 Apr 2018 05:14:18 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[TensorFlow Hub | TensorFlow]]></title>
            <description><![CDATA[<article><h1>TensorFlow Hub | TensorFlow</h1><p>import tensorflow as tf import tensorflow_hub as hub with tf.Graph().as_default(): embed = hub.Module(&quot;https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1&quot;) embeddings = embed([&quot;A long sentence.&quot;, &quot;single-word&quot;, &quot;http://example.com&quot;]) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) sess.run(tf.tables_initializer()) print(sess.run(embeddings))</p><img src="https://www.tensorflow.org/images/tf_logo_social.png"></article>]]></description>
            <link>https://www.tensorflow.org/hub/</link>
            <guid isPermaLink="false">10fe94b1-fcd9-400f-88be-744ba4afc381</guid>
            <pubDate>Mon, 02 Apr 2018 05:14:15 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[A 21-year-old Swedish AI prodigy wants to revolutionize the $6 trillion education industry - and Tim Cook is impressed]]></title>
            <description><![CDATA[<article><h1>A 21-year-old Swedish AI prodigy wants to revolutionize the $6 trillion education industry - and Tim Cook is impressed</h1><p>Sana Labs is an education tech startup founded by Joel Hellermark, 21. It provides an artificial-intelligence platform designed to individualize a student&apos;s learning in subjects like language and math. Applying AI to education has so far proved difficult, and Sana Labs hopes its scalable platform will change that.</p><img src="http://static1.uk.businessinsider.com/image/59bfe4a3ba785e0bff4bf6a0-2400/gettyimages-846152428.jpg"></article>]]></description>
            <link>http://uk.businessinsider.com/21-year-old-ai-prodigy-wants-to-revolutionize-the-education-industry-2018-3?r=US&amp;IR=T&amp;utm_content=buffer92cb5&amp;utm_medium=social&amp;utm_source=facebook.com&amp;utm_campaign=buffer-ti</link>
            <guid isPermaLink="false">6b3a5ba3-eee6-4949-bec1-15d972824f9e</guid>
            <pubDate>Mon, 02 Apr 2018 05:14:13 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Machine Learning Crash Course | Google Developers]]></title>
            <description><![CDATA[<article><h1>Machine Learning Crash Course | Google Developers</h1><p>Educational resources for machine learning</p><img src="https://developers.google.com/machine-learning/crash-course/images/mlcc-hero.png"></article>]]></description>
            <link>https://developers.google.com/machine-learning/crash-course/</link>
            <guid isPermaLink="false">cb08607c-e077-429d-8c3c-e9722401a5fd</guid>
            <pubDate>Sat, 03 Mar 2018 12:24:31 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Algorithmia - Open Marketplace for Algorithms]]></title>
            <description><![CDATA[<article><h1>Algorithmia - Open Marketplace for Algorithms</h1><p>Algorithmia makes applications smarter, by building a community around algorithm development, where state of the art algorithms are always live and accessible to anyone.</p><img src="https://algorithmia.com/static/img/Danku_diagram.3d32550.png"></article>]]></description>
            <link>https://algorithmia.com/research/ml-models-on-blockchain</link>
            <guid isPermaLink="false">aa4c3da8-da9c-4905-849d-26edf40aa87b</guid>
            <pubDate>Wed, 28 Feb 2018 07:27:01 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Changing machine learning experiences: Project Trillium]]></title>
            <description><![CDATA[<article><h1>Changing machine learning experiences: Project Trillium</h1><p>Imagine you&apos;re 30 meters down, diving above a reef surrounded by amazing-looking creatures and wondering what species the little yellow fish with the silver stripes is. You could fumble around for a fish chart, if you have one, but what you really want is an easier and faster solution.</p><img src="https://community.arm.com/cfs-file/__key/communityserver-blogs-components-weblogfiles/00-00-00-21-42/Arm-robot-ML-launch-image2.jpg"></article>]]></description>
            <link>https://community.arm.com/processors/b/blog/posts/ai-project-trillium?utm_source=Social-organic&amp;utm_medium=LInkedIn&amp;utm_campaign=MachineLearning</link>
            <guid isPermaLink="false">0426a9a8-5cca-40be-9480-2450281e2c4f</guid>
            <pubDate>Tue, 13 Feb 2018 15:34:48 GMT</pubDate>
        </item>
    </channel>
</rss>